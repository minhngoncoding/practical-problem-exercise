


import math
import numpy as np
import pandas as pd


train = pd.read_csv("../data/train.csv")


print(train)


def entropy(labels):
    total = len(labels)
    if total == 0:
        return 0
        
    counts = labels.value_counts()
    # print(total, counts)

    return -sum((count / total) * math.log2(count / total) for count in counts)
    





# Full dataset entropy
full_entropy = entropy(train["RiskLevel"])


full_entropy


# Split the data where CreditScore <=650
left_split = train[train['CreditScore'] <= 650]
right_split = train[train['CreditScore'] > 650]


print(left_split, right_split)


weighted_entropy = (len(left_split) / len(train)) * entropy(left_split['RiskLevel']) + \
                   (len(right_split) / len(train)) * entropy(right_split['RiskLevel'])


print(weighted_entropy)


info_gain = full_entropy - weighted_entropy


print(f"Full Entropy: {full_entropy:.4f}")
print(f"Left Split Entropy (<= 650): {entropy(left_split['RiskLevel']):.4f}")
print(f"Right Split Entropy (> 650): {entropy(right_split['RiskLevel']):.4f}")
print(f"Information Gain for splitting at CreditScore = 650: {info_gain:.4f}")








# All credit scores and corresponding ages
ages = train['Age'].values
credit_scores = train['CreditScore'].values


print(ages)


# Total variance before split
mean_total = np.mean(credit_scores)
var_total = np.mean((credit_scores - mean_total) ** 2)


print(var_total)


# Split by Age <= 35 and Age > 35
left = credit_scores[ages <= 35]
right = credit_scores[ages > 35]


print(left)
print(right)


var_left = np.mean((left - np.mean(left)) ** 2)
var_right = np.mean((right - np.mean(right)) ** 2)


print(var_left)
print(var_right)


weighted_var_after = (len(left) / len(credit_scores)) * var_left + \
                     (len(right) / len(credit_scores)) * var_right





var_reduction = var_total - weighted_var_after
var_reduction



